## Benchmarking Hadoop and Spark on the Multiple Paltforms

### The Wordcount application in Java and Python were run on the following platforms:

### Raspberry Pi Cluster 
Hadoop Spark Yarn
* https://github.com/cloudmesh-community/hid-sp18-412/tree/master/project-code/hadoop-spark-yarn

Apache Spark Standalone
* https://github.com/cloudmesh-community/hid-sp18-412/tree/master/project-code/spark-standalone

Ubuntu-Docker 
* https://github.com/cloudmesh-community/hid-sp18-412/tree/master/project-code/docker-spark-ubuntu-platform

### The initial configurations need to be performed in the raspberry Pi nodes in order to install the Apache Hadoop and Apache Spark in standalone mode, that was developed by our team at the following link:

* https://github.com/cloudmesh-community/hid-sp18-412/tree/master/dep

	